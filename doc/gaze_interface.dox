/**
@page icub_gaze_interface The Gaze Interface

\author Ugo Pattacini

\section sec_gaze_contents Contents

- \ref sec_gaze_intro
- \ref sec_gaze_dependencies
- \ref sec_gaze_runningserver
- \ref sec_gaze_opencloseinterface
- \ref sec_gaze_useinterface
- \ref sec_gaze_contextswitch
- \ref sec_gaze_eventscallbacks
- \ref sec_gaze_siminterface


\section sec_gaze_intro Introduction

The YARP <b>Gaze Interface</b> provides an abstract layer to control the iCub gaze in a bio-plausible way, moving the neck
and the eyes independently and performing saccades, pursuit, vergence, OCR (oculo-collic reflex) and VOR (vestibulo-ocular reflex
relying on inertial data). 

Essentially the interface exports all the functionalities given by the \ref iKinGazeCtrl module directly from within the
code without having to be concerned with the communication protocol done via YARP ports. Thus, the user is warmly invited
to visit the iKinGazeCtrl \ref iKinGazeCtrl "page" where more detailed descriptions can be found.

\note <b>If you're going to use this controller for your work, please quote it within any resulting publication</b>.


\section sec_gaze_dependencies Dependencies

In order to use the Gaze Interface, make sure that the following steps are done:

-# Update YARP and iCub repositories.
-# Compile YARP (always a good practice).
-# Install <a href="http://eris.liralab.it/wiki/Installing_IPOPT">Ipopt</a>.
-# Compile the iCub repository with the switch <b>ENABLE_icubmod_gazecontrollerclient</b> enabled: this will make
   the client part of the interface available. The server part is represented by the module \ref iKinGazeCtrl itself.


\section sec_gaze_runningserver Running the Gaze Server

Launch:
\code
iKinGazeCtrl
\endcode

The server will load its parameters from the default configuration file (which can be overridden by the <i>context</i> and
the <i>from</i> command-line options) containing information on the camera intrinsic parameters which are required to use some
of the methods provided by the Gaze Interface, and specifically the <i>lookAtMonoPixel()</i> and <i>lookAtStereoPixel()</i> method. \n
Furthermore, by using the installed copy of <i>$ICUB_ROOT/main/app/iCubStartup/scripts/iCubStartup.xml</i> application the user is
also able to launch the gaze server contextually with the iCubInterface module.


\section sec_gaze_opencloseinterface Opening and Closing the Gaze Interface

The Gaze Interface can be opened as a normal YARP interface resorting to the <i>PolyDriver</i> class but before
this the user has to enforce the dependency of his project from the iCub hardware modules collection.

To achieve that, the following lines have to be included in the <i>CMakeLists.txt</i> file whenever you intend to put
your project within the iCub repository:
\code
target_link_libraries(${PROJECTNAME} ... icubmod ...)
\endcode 

On the contrary, if you are developing your module externally to the iCub repository, make sure to include the 
following lines:
\code
find_package(ICUB)
...
include_directories(... ${ICUB_INCLUDE_DIRS} ...)
...
target_link_libraries(${PROJECTNAME} ... icubmod ...)
\endcode 

Besides, it is also required to insert the following lines within the code in order to correctly initialize the cartesian
client controller:
\code
...
#include <yarp/dev/all.h>
YARP_DECLARE_DEVICES(icubmod)
...

int main()
{
    YARP_REGISTER_DEVICES(icubmod)
    ...
}
\endcode

You are now able to open the Gaze Interface in the usual way:
\code 
Property option;
option.put("device","gazecontrollerclient");
option.put("remote","/iKinGazeCtrl");
option.put("local","/client/gaze");
 
PolyDriver clientGazeCtrl(option);

IGazeControl *igaze=NULL;

if (clientGazeCtrl.isValid()) {
   clientGazeCtrl.view(igaze);
}
\endcode

When you are done with controlling the robot you can explicitly close the device (or just let the destructor do it for you): 
\code
clientGazeCtrl.close();
\endcode


\section sec_gaze_useinterface Using the Gaze Interface

The YARP Gaze Interface is fully documented <a href="http://eris.liralab.it/yarpdoc/classyarp_1_1dev_1_1IGazeControl.html">here</a>.
It makes use of three different coordinate systems that enable the user to control the robot's gaze as detailed hereafter.

\subsection subsec_gaze_cartcoorsystem Expressing the fixation point in Cartesian Coordinates
This coordinate system is the same as the one the \ref icub_cartesian_interface "Cartesian Interface" relies on and complies with the
<a href="http://eris.liralab.it/wiki/ICubForwardKinematics">wiki</a> specifications; it lets the user to give the target
location where to gaze at with respect to the root reference frame attached to the robot's waist.

The following snippet of code shows how to command the gaze in the cartesian space and to retrieve the current configuration.

\code
#include <iCub/ctrl/ctrlMath.h>
...
Vector fp(3);
fp[0]=-0.50;                                    // x-component [m]
fp[1]=+0.00;                                    // y-component [m]
fp[2]=+0.35;                                    // z-component [m]

igaze->lookAtFixationPoint(fp);                 // move the gaze to the desired fixation point
igaze->waitMotionDone();                        // wait until the operation is done

Vector x;
igaze->getFixationPoint(x);                     // retrieve the current fixation point

cout<<"final error = "<<norm(fp-x)<<endl;       // return a measure of the displacement error
\endcode


\subsection subsec_gaze_absangcoorsystem Expressing the fixation point in Absolute Angular Coordinate System
This coordinate system is an absolute head-centered angular reference frame as explained below:
- <i>Angular</i> means that it makes use of the azimuth, elevation and vergence that are angular quantities.
- <i>Head-Centered</i> means that the frame is attached at the middle point between the two cameras owning the same set of three axes.
- <i>Absolute</i> indicates that it remains still irrespective of the robot motion and it refers to the position of the head
  when the robot is in rest configuration (i.e. torso and head angles zeroed).
  
For instance, to specify a desired location where to look at in this coordinate system, one can write:
\code
Vector ang(3);
ang[0]=+10.0;                   // azimuth-component [deg]
ang[1]=-05.0;                   // elevation-component [deg]
ang[2]=+20.0;                   // vergence-component [deg]

igaze->lookAtAbsAngles(ang);    // move the gaze

...

igaze->getAngles(ang);          // get the current angular configuration
\endcode


\subsection subsec_gaze_relangcoorsystem Expressing the fixation point in Relative Angular Coordinate System
Also the relative angular coordinate system is available which is basically the same as the absolute one but refers to the current
configuration of the head-centered frame. Hence we can use:
\code
Vector ang(3);
ang[0]=+10.0;   // azimuth-relative component wrt the current configuration [deg]
ang[1]=-05.0;   // elevation-relative component wrt the current configuration [deg]
ang[2]=+20.0;   // vergence-relative component wrt the current configuration [deg]

igaze->lookAtRelAngles(ang);    // move the gaze wrt the current configuration
\endcode


\subsection subsec_gaze_monopixelcoorsystem Expressing the fixation point in pixel coordinates (monocular approach)
The user can also command the gaze by specifying a location within the image plane of one camera as follows:
\code
int camSel=0;   // select the image plane: 0 (left), 1 (right)

Vector px(2);   // specify the pixel where to look
px[0]=160.0;
px[1]=120.0;

double z=1.0;   // distance [m] of the object from the image plane (extended to infinity): yes, you probably need to guess, but it works pretty robustly

igaze->lookAtMonoPixel(camSel,px,z);    // look!
\endcode
What the interface will internally execute is to retrieve the corresponding 3D point through a call to <i>get3DPoint()</i> to then use
this result to command an equivalent cartesian displacement as in the following:
\code
Vector x;
igaze->get3Dpoint(camSel,px,z,x);
igaze->lookAtFixationPoint(x);
\endcode
The benefit of <i>lookAtMonoPixel()</i> method is clearly that the time for the rpc communication is saved, hence it is particularly designed for control
in streaming mode; on the other hand, the knowledge of the cartesian point remains hidden to the user, unless it is retrieved at the end of the
motion through a call to <i>getFixationPoint()</i>. \n
Alternatively, one can think to rely on the vergence angle given in degree in place of the the component z, accountin for a different way of expressing
distances from the eyes. To this end, the user can call the proper method <i>lootAtMonoPixelWithVergence(camSel,px,ver)</i>.


\subsection subsec_gaze_stereopixelcoorsystem Expressing the fixation point in pixel coordinates (stereo approach)
The same thing can be achieved also by exploiting the stereo vision:
\code
Vector c(2), pxl(2), pxr(2);
c[0]=160.0;     // center of image plane
c[1]=120.0;

bool converged=false;
while (!converged)
{
    pxl[0]=...;         // specify somehow the pixel within the left image plane
    pxl[1]=...;

    pxr[0]=...;         // specify somehow the pixel within the right image plane
    pxr[1]=...;

    igaze->lookAtStereoPixels(pxl,pxr);                 // look!

    converged=(0.5*(norm(c-pxl)+norm(c-pxr))<5);        // recompute somehow the convergence status
}
\endcode
Of course, the matching problem between pixels of different image planes is left to the user, who has also to
provide a continuous visual feedback while converging to the target.


\subsection subsec_gaze_geometrypixels Geometry of pixels
It might be useful sometimes to perform an homography in order to retrieve the projection of a pixel into a plane specified
in the 3D space: let's think for instance to the context of the robot presented with a number of objects that all lie on a table.
The table introduces a constraint that allows determining the component z of the point in case the monocular approach is used.
\code
int camSel=0;   // select the image plane: 0 (left), 1 (right)

Vector px(2);   // specify the pixel where to look
px[0]=160.0;
px[1]=120.0;

Vector plane(4);  // specify the plane in the root reference frame as ax+by+cz+d=0; z=-0.12 in this case
plane[0]=0.0;     // a
plane[1]=0.0;     // b
plane[2]=1.0;     // c
plane[3]=0.12;    // d

Vector x;
igaze->get3DPointOnPlane(camSel,px,plane,x);    // get the projection
\endcode
It is possible to execute a triangulation to find from the pixels in the images the corresponding 3D point in the space. This problem is
solved through a least-squares minimization.
\code
Vector pxl(2), pxr(2);
pxl[0]=...;         // specify somehow the pixel within the left image plane
pxl[1]=...;

pxr[0]=...;         // specify somehow the pixel within the right image plane
pxr[1]=...;

Vector x;
igaze->triangulate3DPoint(pxl,pxr,x);
\endcode
Importantly, the triangulation is strongly affected by uncertainties in the cameras alignment, so that, unless these unknowns are
perfectly compensated, to fixate in stereo mode it is advisable to rely on the method <i>lookAtStereoPixels()</i>.


\subsection subsec_gaze_fastsaccadicmode Fast Saccadic Mode
The user has the possibility to enable the fast saccadic mode that employs the low level position control in order to generate
very fast saccadic movements of the eyes. To do that one can simply do the following:
\code
igaze->setSaccadesStatus(true);
\endcode
After a saccade is executed, the next saccadic movement can be performed only after a given inhibition period of time, that in turn
can be retrieved and/or tuned relying on specific methods (i.e. <i>get/setSaccadesInhibitionPeriod()</i>). \n
<i>Caveat</i>: vision processing algorithms that assume the continuity of the images flow might be heavily affected by saccades.


\section sec_gaze_contextswitch Context Switch

We define here the <i>context</i> as the configuration in which the controller operates: therefore the context includes
the current tracking mode, the eyes and neck trajectory execution time and so on.
Obviously the controller performs the same action differently depending on the current context.
A way to easily switch among contexts is to rely on <i>storeContext()</i> and <i>restoreContext()</i> methods as follows:
\code
igaze->setEyesTrajTime(0.5);            // here the user prepares the context
igaze->setTrackingMode(true);
igaze->bindNeckPitch();
...
int context_0;
igaze->storeContext(&context_0);        // latch the context

igaze->setNeckTrajTime(1.5);            // at certain point the user may want the controller to
igaze->clearNeckPitch();                // perform some actions with different configuration
igaze->lookAtFixationPoint(fp);         
...

igaze->restoreContext(context_0);       // ... and then retrieve the stored context_0
igaze->lookAtFixationPoint(fp);         // now the controller performs the same action but within the context_0
\endcode
Unless the user needs the interface just for logging purposes, it's a good rule to store the context at the initialization
of his module in order to then restore it at releasing time to preserve the controller configuration.


\section sec_gaze_eventscallbacks Events Callbacks

The Gaze Interface provides also an easy way to register events callbacks. For example, an event might be represented by the onset of
the movement when the controller gets activated or the end of the movement itself. The user can then attach a callback to any event generated
by the interface. \n
It is required to inherit from a specific class <i>GazeEvent</i> that handles events and override the <i>gazeEventCallback()</i> method.
\code
class MotionDoneEvent : public GazeEvent
{
public:
   MotionDoneEvent()
   {
      gazeEventParameters.type="motion-done";      // select here the event type we want to listen to
   }

   virtual void gazeEventCallback()
   {
      cout<<"motion complete"<<endl;
   }
};

MotionDoneEvent event;
igaze->registerEvent(event);                       // the tag "motion-done" identifies the event to be notified
igaze->lootAtFixationPoint(fp);                    // as soon as the motion is complete, the callback will print out the message
\endcode

To know which events are available for notification, the user can do:
\code
Bottle info;
igaze->getInfo(info);
cout<<info.find("events").asList()->toString().c_str()<<endl;
\endcode
The special wildcard "*" can be used to assign a callback to any event, regardless of its type.


\section sec_gaze_siminterface The Simulator and the Gaze Interface

The Gaze Interface is already fully operative with the robot simulator: you only need to select the proper configuration file. \n
To do that, type the following:
\code
iKinGazeCtrl --from configSim.ini
\endcode

A working example is available under
\code
tutorials/src/tutorial_gaze_interface.cpp
\endcode
*/

